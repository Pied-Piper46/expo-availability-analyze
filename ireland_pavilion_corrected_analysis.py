#!/usr/bin/env python3
"""
ã‚¢ã‚¤ãƒ«ãƒ©ãƒ³ãƒ‰ãƒ‘ãƒ“ãƒªã‚ªãƒ³ä¿®æ­£ç‰ˆåˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ

15åˆ†é–“éš”ã§ã®é‡è¤‡é™¤å»ã‚’å®Ÿè£…ã—ã€ã‚ˆã‚Šå®Ÿç”¨çš„ãªè§£æ”¾äºˆæ¸¬åˆ†æã‚’å®Ÿè¡Œ
- åŒä¸€ãƒ‘ãƒ“ãƒªã‚ªãƒ³ã§15åˆ†ä»¥å†…ã®è§£æ”¾ã¯1å›ã®è§£æ”¾ã‚¤ãƒ™ãƒ³ãƒˆã¨ã—ã¦æ‰±ã†
- ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦–ç‚¹ã§ã®å®Ÿç”¨çš„ãªè§£æ”¾ã‚¿ã‚¤ãƒŸãƒ³ã‚°åˆ†æ
- äºˆæ¸¬ã«å½¹ç«‹ã¤è§£æ”¾ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æŠ½å‡º
"""

import json
import argparse
from datetime import datetime, timedelta
from collections import defaultdict, Counter
import statistics
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib import rcParams
import seaborn as sns

# ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = ['DejaVu Sans', 'sans-serif']
rcParams['axes.unicode_minus'] = False

# ãƒ‘ãƒ“ãƒªã‚ªãƒ³æƒ…å ±
PAVILION_INFO = {
    'C060': {
        'name': 'ã‚¢ã‚¤ãƒ«ãƒ©ãƒ³ãƒ‰ç”Ÿæ¼”å¥',
        'color': '#ff6b6b'
    },
    'C063': {
        'name': 'ã‚¢ã‚¤ãƒ«ãƒ©ãƒ³ãƒ‰ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ–',
        'color': '#4ecdc4'
    },
    'C066': {
        'name': 'ã‚¢ã‚¤ãƒ«ãƒ©ãƒ³ãƒ‰ç”Ÿæ¼”å¥ãªã—',
        'color': '#45b7d1'
    }
}

def load_data():
    """JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    try:
        with open('availability_log.jsonl', 'r', encoding='utf-8') as file:
            data = [json.loads(line) for line in file]
        print(f"âœ… {len(data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        return data
    except FileNotFoundError:
        print("âŒ availability_log.jsonl ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return []
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def parse_timestamp(timestamp_str):
    """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ãƒ‘ãƒ¼ã‚¹ï¼ˆUTC â†’ JSTå¤‰æ›ï¼‰"""
    try:
        utc_time = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
        jst_time = utc_time + timedelta(hours=9)
        return jst_time
    except:
        return None

def preprocess_releases_for_prediction(data, interval_minutes=15):
    """
    äºˆæ¸¬ç”¨ã®è§£æ”¾ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
    åŒä¸€ãƒ‘ãƒ“ãƒªã‚ªãƒ³ã§15åˆ†ä»¥å†…ã®è§£æ”¾ã‚’1å›ã®è§£æ”¾ã‚¤ãƒ™ãƒ³ãƒˆã¨ã—ã¦æ‰±ã†
    """
    target_pavilions = ['C060', 'C063', 'C066']
    raw_releases = defaultdict(list)

    # ã¾ãšç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’åé›†
    for entry in data:
        if entry.get('pavilion_code') in target_pavilions and entry.get('status') == 0:
            timestamp = parse_timestamp(entry['timestamp'])
            if timestamp:
                raw_releases[entry['pavilion_code']].append({
                    'timestamp': timestamp,
                    'time_slot': entry['time_slot'],
                    'date': timestamp.date(),
                    'time': timestamp.time()
                })

    # æ™‚ç³»åˆ—ã§ã‚½ãƒ¼ãƒˆ
    for pavilion_code in raw_releases:
        raw_releases[pavilion_code].sort(key=lambda x: x['timestamp'])

    print(f"ğŸ“Š ç”Ÿãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ:")
    for code in target_pavilions:
        count = len(raw_releases[code])
        print(f"  - {PAVILION_INFO[code]['name']} ({code}): {count}å›ï¼ˆé‡è¤‡é™¤å»å‰ï¼‰")

    # 15åˆ†é–“éš”ã§ã®é‡è¤‡é™¤å»
    filtered_releases = defaultdict(list)
    removed_count = defaultdict(int)

    for pavilion_code, releases in raw_releases.items():
        if not releases:
            continue

        last_release_time = None

        for release in releases:
            current_time = release['timestamp']

            # å‰å›è§£æ”¾ã‹ã‚‰15åˆ†çµŒéã—ã¦ã„ã‚Œã°æœ‰åŠ¹ãªè§£æ”¾ã¨ã™ã‚‹
            if (last_release_time is None or
                (current_time - last_release_time).total_seconds() >= interval_minutes * 60):

                filtered_releases[pavilion_code].append(release)
                last_release_time = current_time
            else:
                removed_count[pavilion_code] += 1

    print(f"\nğŸ”§ 15åˆ†é–“éš”é‡è¤‡é™¤å»çµæœ:")
    for code in target_pavilions:
        original = len(raw_releases[code])
        filtered = len(filtered_releases[code])
        removed = removed_count[code]
        reduction_rate = (removed / original * 100) if original > 0 else 0

        print(f"  - {PAVILION_INFO[code]['name']} ({code}):")
        print(f"    åŸãƒ‡ãƒ¼ã‚¿: {original}å› â†’ ä¿®æ­£å¾Œ: {filtered}å›")
        print(f"    é™¤å»: {removed}å› ({reduction_rate:.1f}%å‰Šæ¸›)")

    return filtered_releases

def calculate_corrected_distribution(release_data):
    """ä¿®æ­£ç‰ˆç¢ºç‡åˆ†å¸ƒã‚’è¨ˆç®—"""
    pavilion_distributions = {}

    # 15åˆ†å˜ä½ã®æ™‚é–“ãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆ
    time_labels = []
    for hour in range(10, 20):  # 10:00-19:45
        for minute in [0, 15, 30, 45]:
            start_time = f"{hour:02d}:{minute:02d}"
            end_hour = hour if minute < 45 else hour + 1
            end_minute = minute + 15 if minute < 45 else 0
            end_time = f"{end_hour:02d}:{end_minute:02d}"
            time_labels.append(f"{start_time}~{end_time}")

    for pavilion_code, releases in release_data.items():
        if not releases:
            continue

        total_releases = len(releases)
        distribution = {}

        # å„æ™‚é–“å¸¯ã§ã®è§£æ”¾å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        time_counts = defaultdict(int)

        for release in releases:
            time_obj = release['time']
            hour = time_obj.hour
            minute = time_obj.minute

            # 15åˆ†å˜ä½ã«ä¸¸ã‚ã‚‹
            interval_minute = (minute // 15) * 15

            if 10 <= hour < 20:  # å–¶æ¥­æ™‚é–“å†…ã®ã¿
                start_time = f"{hour:02d}:{interval_minute:02d}"
                end_hour = hour if interval_minute < 45 else hour + 1
                end_minute = interval_minute + 15 if interval_minute < 45 else 0

                if end_hour < 20:  # 20:00æœªæº€ã¾ã§
                    end_time = f"{end_hour:02d}:{end_minute:02d}"
                    time_range = f"{start_time}~{end_time}"
                    time_counts[time_range] += 1

        # ç¢ºç‡åˆ†å¸ƒã‚’è¨ˆç®—
        for time_label in time_labels:
            count = time_counts.get(time_label, 0)
            percentage = (count / total_releases * 100) if total_releases > 0 else 0

            distribution[time_label] = {
                'count': count,
                'percentage': percentage
            }

        pavilion_distributions[pavilion_code] = {
            'pavilion_name': PAVILION_INFO[pavilion_code]['name'],
            'total_releases': total_releases,
            'distribution': distribution,
            'time_labels': time_labels
        }

    return pavilion_distributions

def create_comparison_visualization(original_data, corrected_data):
    """ä¿®æ­£å‰å¾Œã®æ¯”è¼ƒå¯è¦–åŒ–"""
    fig, axes = plt.subplots(3, 2, figsize=(20, 15))
    fig.suptitle('è§£æ”¾ãƒ‡ãƒ¼ã‚¿ä¿®æ­£å‰å¾Œã®æ¯”è¼ƒåˆ†æ', fontsize=16, fontweight='bold')

    pavilion_codes = ['C060', 'C063', 'C066']

    for idx, pavilion_code in enumerate(pavilion_codes):
        # ä¿®æ­£å‰ã®ãƒ‡ãƒ¼ã‚¿
        if pavilion_code in original_data:
            orig_releases = original_data[pavilion_code]
            orig_hourly = defaultdict(int)
            for release in orig_releases:
                hour = release['time'].hour
                if 10 <= hour < 20:
                    orig_hourly[hour] += 1
        else:
            orig_hourly = {}

        # ä¿®æ­£å¾Œã®ãƒ‡ãƒ¼ã‚¿
        if pavilion_code in corrected_data:
            corr_releases = corrected_data[pavilion_code]
            corr_hourly = defaultdict(int)
            for release in corr_releases:
                hour = release['time'].hour
                if 10 <= hour < 20:
                    corr_hourly[hour] += 1
        else:
            corr_hourly = {}

        hours = list(range(10, 20))
        orig_counts = [orig_hourly.get(h, 0) for h in hours]
        corr_counts = [corr_hourly.get(h, 0) for h in hours]

        color = PAVILION_INFO[pavilion_code]['color']

        # ä¿®æ­£å‰
        ax1 = axes[idx, 0]
        bars1 = ax1.bar(hours, orig_counts, color=color, alpha=0.7)
        ax1.set_title(f'{PAVILION_INFO[pavilion_code]["name"]} - ä¿®æ­£å‰')
        ax1.set_ylabel('è§£æ”¾å›æ•°')
        ax1.set_xlabel('æ™‚é–“å¸¯')
        ax1.grid(axis='y', alpha=0.3)

        # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
        for bar, count in zip(bars1, orig_counts):
            if count > 0:
                ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                        str(count), ha='center', va='bottom', fontsize=9)

        # ä¿®æ­£å¾Œ
        ax2 = axes[idx, 1]
        bars2 = ax2.bar(hours, corr_counts, color=color, alpha=0.7)
        ax2.set_title(f'{PAVILION_INFO[pavilion_code]["name"]} - ä¿®æ­£å¾Œï¼ˆ15åˆ†é‡è¤‡é™¤å»ï¼‰')
        ax2.set_ylabel('è§£æ”¾å›æ•°')
        ax2.set_xlabel('æ™‚é–“å¸¯')
        ax2.grid(axis='y', alpha=0.3)

        # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
        for bar, count in zip(bars2, corr_counts):
            if count > 0:
                ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                        str(count), ha='center', va='bottom', fontsize=9)

        # Yè»¸ã®ç¯„å›²ã‚’æƒãˆã‚‹
        max_y = max(max(orig_counts) if orig_counts else 0,
                   max(corr_counts) if corr_counts else 0)
        ax1.set_ylim(0, max_y * 1.2)
        ax2.set_ylim(0, max_y * 1.2)

    plt.tight_layout()
    plt.savefig('ireland_comparison_before_after.png', dpi=300, bbox_inches='tight')
    print("âœ… ä¿®æ­£å‰å¾Œæ¯”è¼ƒå›³ã‚’ä¿å­˜: ireland_comparison_before_after.png")

def analyze_weekday_patterns_corrected(release_data):
    """ä¿®æ­£ç‰ˆæ›œæ—¥åˆ¥è§£æ”¾ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"""
    weekday_patterns = {}

    for pavilion_code, releases in release_data.items():
        weekday_counts = defaultdict(int)
        weekday_times = defaultdict(list)

        for release in releases:
            weekday = release['date'].weekday()  # 0=æœˆæ›œæ—¥, 6=æ—¥æ›œæ—¥
            weekday_counts[weekday] += 1
            weekday_times[weekday].append(release['time_slot'])

        weekday_patterns[pavilion_code] = {
            'counts': dict(weekday_counts),
            'times': dict(weekday_times)
        }

    return weekday_patterns

def generate_corrected_report(corrected_distributions, weekday_patterns, release_data, original_totals):
    """ä¿®æ­£ç‰ˆè©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""

    report = """
# ã‚¢ã‚¤ãƒ«ãƒ©ãƒ³ãƒ‰ãƒ‘ãƒ“ãƒªã‚ªãƒ³ä¿®æ­£ç‰ˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ
## 15åˆ†é–“éš”é‡è¤‡é™¤å»ã«ã‚ˆã‚‹å®Ÿç”¨çš„è§£æ”¾äºˆæ¸¬åˆ†æ

### ğŸ“Š ãƒ‡ãƒ¼ã‚¿ä¿®æ­£åŠ¹æœ

ã“ã®åˆ†æã§ã¯ã€**åŒä¸€ãƒ‘ãƒ“ãƒªã‚ªãƒ³ã§15åˆ†ä»¥å†…ã®è§£æ”¾ã‚’1å›ã®è§£æ”¾ã‚¤ãƒ™ãƒ³ãƒˆ**ã¨ã—ã¦æ‰±ã†ã“ã¨ã§ã€
ã‚ˆã‚Šå®Ÿç”¨çš„ãªè§£æ”¾ã‚¿ã‚¤ãƒŸãƒ³ã‚°äºˆæ¸¬ã‚’å¯èƒ½ã«ã—ã¾ã—ãŸã€‚

#### ä¿®æ­£å‰å¾Œã®æ¯”è¼ƒ

| ãƒ‘ãƒ“ãƒªã‚ªãƒ³ | ä¿®æ­£å‰ | ä¿®æ­£å¾Œ | å‰Šæ¸›ç‡ | å‰Šæ¸›ç†ç”± |
|------------|--------|--------|--------|----------|
"""

    for pavilion_code in ['C060', 'C063', 'C066']:
        if pavilion_code in release_data:
            original = original_totals.get(pavilion_code, 0)
            corrected = len(release_data[pavilion_code])
            reduction = original - corrected
            reduction_rate = (reduction / original * 100) if original > 0 else 0

            report += f"| {PAVILION_INFO[pavilion_code]['name']} ({pavilion_code}) | {original}å› | {corrected}å› | {reduction_rate:.1f}% | çŸ­æ™‚é–“ã§ã®é€£ç¶šè§£æ”¾é™¤å» |\n"

    report += "\n### ğŸ¯ ä¿®æ­£å¾Œã®è§£æ”¾æ™‚é–“ç¢ºç‡åˆ†å¸ƒ\n"

    for pavilion_code, data in corrected_distributions.items():
        pavilion_name = data['pavilion_name']
        total_releases = data['total_releases']
        distribution = data['distribution']

        # ç¢ºç‡ã®é«˜ã„æ™‚é–“å¸¯TOP3ã‚’å–å¾—
        sorted_times = sorted(
            [(time, stats) for time, stats in distribution.items() if stats['percentage'] > 0],
            key=lambda x: x[1]['percentage'],
            reverse=True
        )

        report += f"\n#### {pavilion_name} ({pavilion_code})\n"
        report += f"**ä¿®æ­£å¾Œç·è§£æ”¾å›æ•°**: {total_releases}å›\n\n"

        report += "| è§£æ”¾æ™‚é–“å¸¯ | å›æ•° | ç¢ºç‡(%) |\n|------------|------|--------|\n"

        for time_range, stats in sorted_times[:10]:  # TOP10è¡¨ç¤º
            report += f"| {time_range} | {stats['count']}å› | {stats['percentage']:.1f}% |\n"

        if sorted_times:
            top_time = sorted_times[0]
            report += f"\n**æœ€é »å‡ºè§£æ”¾æ™‚é–“**: {top_time[0]} ({top_time[1]['percentage']:.1f}%)\n"

    report += "\n### ğŸ“… ä¿®æ­£å¾Œæ›œæ—¥åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³\n"

    weekdays_jp = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
    for pavilion_code, data in weekday_patterns.items():
        report += f"\n#### {PAVILION_INFO[pavilion_code]['name']} ({pavilion_code})\n"

        counts = data['counts']
        total_releases = sum(counts.values())

        report += "| æ›œæ—¥ | è§£æ”¾å›æ•° | å‰²åˆ(%) |\n|------|----------|----------|\n"

        for i, weekday in enumerate(weekdays_jp):
            count = counts.get(i, 0)
            percentage = (count / total_releases * 100) if total_releases > 0 else 0
            report += f"| {weekday}æ›œæ—¥ | {count}å› | {percentage:.1f}% |\n"

    report += "\n## ğŸš€ äºˆæ¸¬ã¸ã®æ´»ç”¨æ–¹æ³•\n\n"

    report += """
### è§£æ”¾äºˆæ¸¬ã®ç²¾åº¦å‘ä¸Š

ä¿®æ­£å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ä»¥ä¸‹ã®åˆ©ç‚¹ãŒã‚ã‚Šã¾ã™ï¼š

1. **ãƒã‚¤ã‚ºé™¤å»**: çŸ­æ™‚é–“ã§ã®é‡è¤‡è§£æ”¾ã‚’é™¤å»ã—ã€çœŸã®è§£æ”¾ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’æŠ½å‡º
2. **ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦–ç‚¹**: 15åˆ†ä»¥å†…ã®è§£æ”¾ã¯å®Ÿè³ªçš„ã«åŒä¸€ã‚¤ãƒ™ãƒ³ãƒˆã¨ã—ã¦æ‰±ã„ã€å®Ÿç”¨æ€§ã‚’å‘ä¸Š
3. **äºˆæ¸¬ç²¾åº¦**: ã‚ˆã‚Šæ­£ç¢ºãªè§£æ”¾ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚Šã€äº‹å‰æº–å‚™ã®åŠ¹æœã‚’æœ€å¤§åŒ–

### æ¨å¥¨æˆ¦ç•¥

#### C060 (ã‚¢ã‚¤ãƒ«ãƒ©ãƒ³ãƒ‰ç”Ÿæ¼”å¥)
- **æœ€é©æˆ¦ç•¥**: ä¿®æ­£å¾Œã®æœ€é »å‡ºæ™‚é–“å¸¯ã«é›†ä¸­ç›£è¦–
- **äº‹å‰æº–å‚™**: è©²å½“æ™‚é–“ã®5åˆ†å‰ã‹ã‚‰ã‚¹ã‚¿ãƒ³ãƒã‚¤

#### C063 (ã‚¢ã‚¤ãƒ«ãƒ©ãƒ³ãƒ‰ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ–)
- **å¸Œå°‘æ€§é‡è¦–**: é™å®šçš„ãªè§£æ”¾ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ­£ç¢ºã«æŠŠæ¡
- **ç¢ºå®Ÿæ€§å„ªå…ˆ**: é«˜ç¢ºç‡æ™‚é–“å¸¯ã§ã®ç¢ºå®Ÿãªå–å¾—ã‚’ç›®æŒ‡ã™

#### C066 (ã‚¢ã‚¤ãƒ«ãƒ©ãƒ³ãƒ‰ç”Ÿæ¼”å¥ãªã—)
- **ä»£æ›¿æ‰‹æ®µ**: ä»–ãƒ‘ãƒ“ãƒªã‚ªãƒ³ãŒæº€å¸­æ™‚ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
- **æŸ”è»Ÿå¯¾å¿œ**: è¤‡æ•°æ™‚é–“å¸¯ã§ã®åˆ†æ•£ç›£è¦–

"""

    return report

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ­ ã‚¢ã‚¤ãƒ«ãƒ©ãƒ³ãƒ‰ãƒ‘ãƒ“ãƒªã‚ªãƒ³ä¿®æ­£ç‰ˆåˆ†æã‚’é–‹å§‹...")
    print("ğŸ“‹ 15åˆ†é–“éš”é‡è¤‡é™¤å»ã«ã‚ˆã‚‹å®Ÿç”¨çš„è§£æ”¾äºˆæ¸¬åˆ†æ\n")

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    data = load_data()
    if not data:
        return

    # å…ƒãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆã‚’å–å¾—ï¼ˆæ¯”è¼ƒç”¨ï¼‰
    target_pavilions = ['C060', 'C063', 'C066']
    original_totals = {}
    for pavilion_code in target_pavilions:
        count = len([entry for entry in data
                    if entry.get('pavilion_code') == pavilion_code and entry.get('status') == 0])
        original_totals[pavilion_code] = count

    # ä¿®æ­£ç‰ˆå‰å‡¦ç†ï¼ˆ15åˆ†é–“éš”é‡è¤‡é™¤å»ï¼‰
    print("\nğŸ”§ 15åˆ†é–“éš”é‡è¤‡é™¤å»ã‚’å®Ÿè¡Œä¸­...")
    corrected_release_data = preprocess_releases_for_prediction(data, interval_minutes=15)

    # ä¿®æ­£ç‰ˆç¢ºç‡åˆ†å¸ƒè¨ˆç®—
    print("\nğŸ“Š ä¿®æ­£ç‰ˆç¢ºç‡åˆ†å¸ƒã‚’è¨ˆç®—ä¸­...")
    corrected_distributions = calculate_corrected_distribution(corrected_release_data)

    # ä¿®æ­£ç‰ˆæ›œæ—¥åˆ¥åˆ†æ
    print("\nğŸ“… ä¿®æ­£ç‰ˆæ›œæ—¥åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æä¸­...")
    weekday_patterns = analyze_weekday_patterns_corrected(corrected_release_data)

    # æ¯”è¼ƒå¯è¦–åŒ–
    print("\nğŸ“ˆ ä¿®æ­£å‰å¾Œã®æ¯”è¼ƒå¯è¦–åŒ–ã‚’ä½œæˆä¸­...")
    # å…ƒãƒ‡ãƒ¼ã‚¿ã‚‚åŒã˜å½¢å¼ã§æº–å‚™
    original_release_data = defaultdict(list)
    for entry in data:
        if entry.get('pavilion_code') in target_pavilions and entry.get('status') == 0:
            timestamp = parse_timestamp(entry['timestamp'])
            if timestamp:
                original_release_data[entry['pavilion_code']].append({
                    'timestamp': timestamp,
                    'time': timestamp.time(),
                    'date': timestamp.date()
                })

    create_comparison_visualization(original_release_data, corrected_release_data)

    # ä¿®æ­£ç‰ˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    print("\nğŸ“ ä¿®æ­£ç‰ˆè©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
    corrected_report = generate_corrected_report(
        corrected_distributions, weekday_patterns, corrected_release_data, original_totals)

    with open('ireland_pavilion_corrected_report.md', 'w', encoding='utf-8') as f:
        f.write(corrected_report)

    # ä¿®æ­£ç‰ˆç¢ºç‡åˆ†å¸ƒHTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆç”¨ã«å…ƒã®pavilion_analyzer.pyã‚’æ›´æ–°
    print("\nğŸ¨ ä¿®æ­£ç‰ˆHTMLãƒ¬ãƒãƒ¼ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ä¸­...")

    # ä¿®æ­£ç‰ˆãƒ‡ãƒ¼ã‚¿ã‚’JSONã¨ã—ã¦ä¿å­˜ï¼ˆå…ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ä½¿ç”¨ã™ã‚‹ãŸã‚ï¼‰
    corrected_data_for_html = {}
    for pavilion_code, data in corrected_distributions.items():
        corrected_data_for_html[pavilion_code] = data

    with open('corrected_distributions.json', 'w', encoding='utf-8') as f:
        json.dump(corrected_data_for_html, f, ensure_ascii=False, indent=2, default=str)

    print("âœ… ä¿®æ­£ç‰ˆåˆ†æå®Œäº†!")
    print("ğŸ“ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«:")
    print("  - ireland_comparison_before_after.png (ä¿®æ­£å‰å¾Œæ¯”è¼ƒ)")
    print("  - ireland_pavilion_corrected_report.md (ä¿®æ­£ç‰ˆè©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ)")
    print("  - corrected_distributions.json (ä¿®æ­£ç‰ˆHTMLãƒ¬ãƒãƒ¼ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿)")
    print("\nğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("  - pavilion_analyzer.pyã‚’æ›´æ–°ã—ã¦ä¿®æ­£ç‰ˆHTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã§ãã¾ã™")

if __name__ == "__main__":
    main()